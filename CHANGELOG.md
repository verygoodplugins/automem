# Changelog

All notable changes to AutoMem will be documented in this file.

## [0.7.0] - 2025-10-17

### üåâ MCP over SSE Sidecar

#### Added - Hosted MCP Server via SSE
- Exposes AutoMem as an MCP server over SSE for cloud clients (ChatGPT, ElevenLabs Agents)
- Endpoints:
  - `GET /mcp/sse` ‚Äî SSE stream (server ‚Üí client); auth via `Authorization: Bearer`, `X-API-Key`, or `?api_key=`
  - `POST /mcp/messages?sessionId=<id>` ‚Äî Client ‚Üí server JSON-RPC messages
  - `GET /health` ‚Äî Sidecar health probe
- Implementation: Node 18 + `@modelcontextprotocol/sdk` with JSON-RPC tool handlers mapping to AutoMem API
- Keepalive: Heartbeats every 20s to avoid idle proxy timeouts

#### Security & Auth
- Preferred auth: `Authorization: Bearer <AUTOMEM_API_TOKEN>`
- Also supports: `X-API-Key` and `?api_key=` (URL tokens may appear in logs; prefer headers)

#### Documentation
- New: `docs/MCP_SSE.md` with deployment, auth, and troubleshooting
- README updated to link SSE sidecar alongside the NPM MCP bridge

### üöÄ Deployment

#### Railway Template Enhancements
- Template now provisions 3 services: `automem-api`, `automem-mcp-sse`, and `FalkorDB`
- `automem-mcp-sse` preconfigured with `AUTOMEM_ENDPOINT` ‚Üí `http://${{automem-api.RAILWAY_PRIVATE_DOMAIN}}`
- Health checks added for the sidecar service
- Fixed: Corrected Dockerfile path in `mcp-sse-server/railway.json`
- Added: `package-lock.json` for reproducible SSE builds

### üìä Benchmarks

#### Added - LoCoMo Benchmark Integration
- End-to-end evaluation flow, docs (`docs/LOCOMO_BENCHMARK.md`), and test harness
- Make targets for local and live (Railway) runs
- Initial optimization phases (1‚Äì2.5) implemented and documented

### üìù Documentation
- INSTALLATION: One‚Äëclick Railway section updated to reflect new SSE service
- README: Added SSE sidecar docs link under MCP and Documentation sections

### üìÅ Files Modified
- `mcp-sse-server/`: `server.js`, `Dockerfile`, `package.json`, `package-lock.json`, `railway.json`
- `docs/`: `MCP_SSE.md`, `LOCOMO_BENCHMARK.md`
- `railway-template.json`
- `INSTALLATION.md`, `README.md`

### Commits Since 0.6.0
- Add MCP SSE sidecar and LoCoMo quick wins
- Add MCP SSE server deployment config for Railway
- Add multi-auth support to SSE server (Bearer, X-API-Key, query param)
- Add package-lock.json for mcp-sse-server
- Fix Dockerfile path in mcp-sse-server railway.json
- Implement LoCoMo benchmark optimizations (Phases 1‚Äì2.5)
- Add LoCoMo benchmark integration and documentation
- Update INSTALLATION.md

## [0.6.0] - 2025-10-14

### üöÄ Performance Optimizations

#### Added - Embedding Batching (40-50% Cost Reduction)
- **Feature**: Batch processing for OpenAI embedding generation
- **Implementation**:
  - New config: `EMBEDDING_BATCH_SIZE` (default: 20) and `EMBEDDING_BATCH_TIMEOUT_SECONDS` (default: 2.0)
  - Created `_generate_real_embeddings_batch()` for bulk embedding generation
  - Rewrote `embedding_worker()` to accumulate and batch-process memories
  - Added `_process_embedding_batch()` helper function
  - Extracted `_store_embedding_in_qdrant()` for reusability
- **Impact**: 
  - 40-50% reduction in API calls and overhead
  - Better throughput during high-memory periods
  - $8-15/year savings at 1000 memories/day

#### Added - Relationship Count Caching (80% Consolidation Speedup)
- **Feature**: LRU cache for relationship counts with hourly invalidation
- **Implementation**:
  - Added `@lru_cache(maxsize=10000)` to `_get_relationship_count_cached_impl()`
  - Cache key includes hour timestamp for automatic hourly refresh
  - Updated `calculate_relevance_score()` to use cached method
- **Impact**:
  - 80% reduction in graph queries during consolidation
  - 5x faster decay consolidation runs
  - Minimal memory overhead with automatic LRU eviction

#### Added - Async Embedding Generation (60% Faster /memory POST)
- **Feature**: Background embedding generation with queue-based processing
- **Implementation**:
  - Embeddings generated asynchronously in worker thread
  - `/memory` POST returns immediately after FalkorDB write
  - Queue-based system prevents blocking API responses
- **Impact**:
  - `/memory` endpoint 60% faster (was 250-400ms, now 100-150ms)
  - Better user experience for high-frequency memory storage
  - No loss in reliability - queued embeddings processed in order

#### Added - Enrichment Stats in /health Endpoint
- **Feature**: Public enrichment metrics in health check (no auth required)
- **Implementation**: Enhanced `/health` endpoint with enrichment section
- **Response Format**:
  ```json
  {
    "enrichment": {
      "status": "running",
      "queue_depth": 12,
      "pending": 15,
      "inflight": 3,
      "processed": 1234,
      "failed": 5
    }
  }
  ```
- **Impact**: Better monitoring and early detection of enrichment backlogs

#### Added - Structured Logging
- **Feature**: Performance metrics in logs for analysis and debugging
- **Implementation**:
  - Added structured logging to `/recall` endpoint with query, latency, results, filters
  - Added structured logging to `/memory` (store) endpoint with type, size, latency, status
  - Logs include `extra={}` dict with machine-parseable fields
- **Impact**: 
  - Easy performance analysis via log aggregation
  - Better debugging for production issues
  - Foundation for metrics dashboards

#### Added - Query Time Metrics
- **Feature**: All API responses now include `query_time_ms` field
- **Implementation**: Added `time.perf_counter()` tracking to all endpoints
- **Impact**: Easy performance monitoring without parsing logs

### üèóÔ∏è Code Quality & Infrastructure

#### Refactored - Utility Module Structure
- **Change**: Extracted reusable helpers from `app.py` into `automem/` package
- **Created Modules**:
  - `automem/utils/graph.py` - Graph query helpers
  - `automem/utils/tags.py` - Tag normalization and processing
  - `automem/utils/text.py` - Text processing utilities
  - `automem/utils/time.py` - Timestamp parsing and formatting
  - `automem/utils/scoring.py` - Relevance scoring functions
- **Impact**: Better code organization, easier testing, reduced duplication

#### Improved - Docker Build
- **Added**: `.dockerignore` file for faster builds
- **Change**: Updated Dockerfile to use new utility module structure
- **Impact**: Smaller Docker images, faster builds

#### Improved - Backup Infrastructure
- **Added**: GitHub Actions workflow for automated backups to S3
- **Added**: Comprehensive backup documentation in `docs/MONITORING_AND_BACKUPS.md`
- **Added**: Backup service deployment guides for Railway
- **Impact**: Better disaster recovery, automated backup schedules

### üêõ Bug Fixes

#### Fixed - Project Name Extraction
- **Issue**: Feature names like "file-ops-automation" were incorrectly extracted as projects
- **Fix**: Added filtering to prevent feature/module names from entity extraction
- **Impact**: Cleaner entity metadata, more accurate project tracking

#### Fixed - /health Endpoint Attribute Error
- **Issue**: `/health` endpoint crashed with `AttributeError: 'EnrichmentStats' object has no attribute 'success_count'`
- **Fix**: Corrected attribute names to `successes` and `failures` (actual class fields)
- **Impact**: `/health` endpoint now works correctly with enrichment stats

### üìÅ Files Modified
- `app.py` - Embedding batching, async generation, health endpoint, structured logging, query timing
- `consolidation.py` - Relationship count caching
- `automem/utils/` - New utility module structure
- `Dockerfile` - Updated for new module structure
- `.dockerignore` - Created for faster builds
- `.github/workflows/backup.yml` - Created automated backup workflow
- `docs/MONITORING_AND_BACKUPS.md` - Updated with comprehensive backup strategies
- `OPTIMIZATIONS.md` - Created comprehensive optimization documentation
- `test-optimizations.sh` - Created test script for validating optimizations

### üìä Performance Comparison

| Metric | Before | After | Improvement |
|--------|--------|-------|-------------|
| OpenAI API calls | 1000/day | ~50-100/day | 40-50% ‚Üì |
| Annual embedding cost | $20-30 | $12-18 | $8-15 saved |
| `/memory` latency | 250-400ms | 100-150ms | 60% faster |
| Consolidation time (10k) | ~5 min | ~1 min | 80% faster |
| Production visibility | Limited | Full metrics | ‚àû better |

### üéì Based On
- Audit by Steve (October 11, 2025)
- Implemented highest-ROI recommendations from audit
- Total implementation time: ~3 hours for optimizations
- Expected ROI: 200-300% in year 1

---

## [0.5.0] - 2025-10-13

### üéØ Major Data Quality Overhaul

#### Fixed - Memory Type Pollution (Critical)
- **Issue**: 490/773 memories (64%) had invalid types from recovery script bug
- **Root Cause**: Recovery script flattened `metadata.type` as top-level property, overwriting actual memory type
- **Fix**: 
  - Added `RESERVED_FIELDS` filter in `scripts/recover_from_qdrant.py` to exclude type, confidence, content, etc.
  - Created `scripts/cleanup_memory_types.py` to reclassify all 490 polluted memories
  - 100% success rate - all memories reclassified to 7 valid types
- **Impact**: Analytics now accurate with only valid memory types (Decision, Pattern, Preference, Style, Habit, Insight, Context)

#### Fixed - Tag-Based Search Not Working
- **Issue**: Tag searches returned 0 results despite memories having tags
- **Root Cause**: Qdrant missing keyword indexes on `tags` and `tag_prefixes` payload fields
- **Fix**: Added `PayloadSchemaType.KEYWORD` indexes in `_ensure_qdrant_collection()`
- **Impact**: Tag filtering now works for both exact and prefix matching

#### Improved - Entity Extraction Quality
**Phase 1 - Error Code Filtering:**
- Added `ENTITY_BLOCKLIST` for HTTP errors (Bad Request, Not Found, etc.)
- Added `ENTITY_BLOCKLIST` for network errors (ECONNRESET, ETIMEDOUT, etc.)

**Phase 2 - Code Artifact Filtering:**
- Block markdown formatting (`- **File:**`, `# Header`, etc.)
- Block class name suffixes (Adapter, Handler, Manager, Service, etc.)
- Block JSON field names (starting with underscore like `_embedded`)
- Block boolean literals (`'false'`, `true`, `null`)
- Block environment variables (all-caps with underscores)
- Block text fragments (strings ending with colons)

**Phase 3 - Project Name Extraction:**
- **Issue**: Project extraction regex required `Project ProjectName` but memories use `project: project-name`
- **Fix**: Added pattern `r"(?:in |on )?project:\s+([a-z][a-z0-9\-]+)"` 
- **Impact**: Now correctly extracts claude-automation-hub, mcp-automem, autochat from session starts

#### Added - LLM-Based Memory Classification
- **Feature**: Hybrid classification system (regex first, LLM fallback)
- **Implementation**: 
  - Enhanced `MemoryClassifier` with `_classify_with_llm()` method
  - Uses GPT-4o-mini for accurate, cost-effective classification
  - Falls back to LLM only when regex patterns don't match (~30% of cases)
- **Reclassification Completed**: 413 memories reclassified with 100% success rate
- **Cost**: $0.04 total for one-time reclassification, ~$0.24/year ongoing (10 memories/day)
- **Accuracy**: 85-95% confidence on technical content, work logs, session starts
- **Script**: Created `scripts/reclassify_with_llm.py` for batch reclassification

#### Added - Automated Backups
- **GitHub Actions**: Workflow runs every 6 hours, backs up to S3
- **Railway Volumes**: Built-in volume backups for redundancy  
- **Dual Storage**: FalkorDB (primary) + Qdrant (backup) provides data resilience
- **Documentation**: Consolidated all backup docs into `docs/MONITORING_AND_BACKUPS.md`

#### Fixed - FalkorDB Data Loss Recovery
- **Issue**: FalkorDB restarted and lost all memories (persistence not working)
- **Recovery**: Used `scripts/recover_from_qdrant.py` to restore 778/780 memories from Qdrant
- **Root Cause Analysis**: `appendonly` was set to `no` instead of `yes`
- **Prevention**: Verified `REDIS_ARGS` in Railway and documented proper persistence configuration

### üìÅ Files Modified
- `app.py` - Enhanced entity extraction, LLM classification, Qdrant indexes
- `scripts/recover_from_qdrant.py` - Fixed metadata field handling
- `scripts/cleanup_memory_types.py` - Created tool for type reclassification
- `scripts/reclassify_with_llm.py` - Created LLM-based reclassification tool
- `docs/MONITORING_AND_BACKUPS.md` - Updated with comprehensive backup strategies
- `docs/RAILWAY_DEPLOYMENT.md` - Updated references to backup documentation
- `README.md` - Updated architecture and documentation links
- `.github/workflows/backup.yml` - Created automated backup workflow

### üìä Impact Summary
- **Memory Types**: 79 invalid types ‚Üí 7 valid types (100% cleanup)
- **Reclassified**: 903 total memories
  - 490 via cleanup script (invalid types ‚Üí valid types)
  - 413 via LLM (fallback "Memory" ‚Üí specific types)
  - 100% success rate on both
- **Final Distribution**: Context (47%), Decision (16%), Insight (13%), Habit (12%), Preference (9%), Pattern (3%), Style (<1%)
- **Entity Quality**: Clean extraction, no error codes or code artifacts
- **Tag Search**: Fully functional with proper indexing
- **Backups**: Automated every 6 hours to S3
- **Data Recovery**: 99.7% recovery rate (778/780) from Qdrant
- **Classification**: Hybrid system with 85-95% LLM confidence

### üöÄ Deployment
All changes deployed to Railway at `automem.up.railway.app`

### üí∞ Cost Analysis
- **LLM Classification**: $0.04 one-time + $0.24/year ongoing (~$0.02/month)
- **S3 Backups**: Minimal (~$0.05/month for storage + lifecycle rules)
- **Qdrant**: Existing free tier (1GB)
- **Railway**: Existing deployment ($5/month hobby plan)

---

## [Prior Releases]
See git history for previous changes.
