# AutoMem: Research-Validated AI Memory ğŸ§ 

> **ğŸ“… November 20, 2025 Update** â€“ Enhanced graph-vector hybrid architecture with improved enrichment pipeline, pattern detection, and deployment workflows. [See what's new](#whats-new-in-november-2025) âš¡

**Graph + Vector architecture proven to match human long-term memory performance.**

```bash
# Deploy in 60 seconds
railway up
# Or run locally
make dev
```

Give your AI persistent memory that actually learns and remembers.

**Quick Navigation:** [What's New](#whats-new-in-november-2025) â€¢ [Architecture](#architecture) â€¢ [Quick Start](#quick-start) â€¢ [Features](#features) â€¢ [API Examples](#api-examples) â€¢ [Connect AI Platforms](#connect-to-ai-platforms) â€¢ [Documentation](#documentation)

---

## The Problem We Solve

AI assistants forget everything between sessions. RAG systems retrieve context but can't learn patterns. Vector databases find similar text but miss relationships.

**You need AI that actually remembers.**

## What AutoMem Does

AutoMem is a **graph-vector memory service** that gives AI assistants durable, relational memory:
- ğŸ§  **Stores memories** with rich metadata, importance scores, and temporal context
- ğŸ” **Recalls with hybrid search** - vector similarity + keyword + tags + time
- ğŸ”— **Builds knowledge graphs** - 11 relationship types between memories
- ğŸ¯ **Learns patterns** - automatic entity extraction, clustering, and consolidation
- âš¡ **Sub-second recall** - even with millions of memories

### Research-Validated Architecture

AutoMem implements principles from:
- **HippoRAG 2** (2025): Graph-vector hybrid for human-like associative memory
- **A-MEM** (2025): Dynamic memory organization with Zettelkasten principles
- **MELODI** (DeepMind, 2025): 8x memory compression without quality loss
- **ReadAgent** (DeepMind, 2024): 20x context extension through gist memories

## What's New in November 2025

ğŸ‰ **Major enhancements to the graph-vector memory system:**

- **ğŸ”— Enhanced Knowledge Graphs** â€“ 11 relationship types now include `PREFERS_OVER`, `EXEMPLIFIES`, and `CONTRADICTS` for richer context modeling
- **ğŸ¤– Smarter Enrichment Pipeline** â€“ Automatic entity extraction (people, tools, projects, concepts) with improved pattern detection
- **ğŸ”„ Background Consolidation** â€“ Memory decay, creative association discovery, clustering, and intelligent forgetting cycles
- **âš¡ Improved Hybrid Search** â€“ Vector similarity + keyword + tags + temporal scoring for better recall accuracy
- **ğŸš€ One-Command Deployment** â€“ Railway deployment simplified with `railway up` - production-ready in 60 seconds
- **ğŸ“Š Better Observability** â€“ Enhanced health monitoring and enrichment status endpoints

[Jump to Quick Start](#quick-start) | [See Full Changelog](CHANGELOG.md)

## Architecture

**Dual-Engine Memory System for Human-Like Recall**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           AutoMem Service (Flask)           â”‚
â”‚   â€¢ REST API for memory lifecycle           â”‚
â”‚   â€¢ Background enrichment pipeline          â”‚
â”‚   â€¢ Consolidation engine                    â”‚
â”‚   â€¢ Automated backups (optional)            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚              â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  FalkorDB   â”‚  â”‚   Qdrant   â”‚
        â”‚   (Graph)   â”‚  â”‚ (Vectors)  â”‚
        â”‚             â”‚  â”‚            â”‚
        â”‚ â€¢ 11 edge   â”‚  â”‚ â€¢ Semantic â”‚
        â”‚   types     â”‚  â”‚   search   â”‚
        â”‚ â€¢ Pattern   â”‚  â”‚ â€¢ 768-d    â”‚
        â”‚   nodes     â”‚  â”‚   vectors  â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Why Two Databases?**
- **FalkorDB (Graph)** â€“ Canonical storage, relationships, and consolidation logic
- **Qdrant (Vectors)** â€“ Semantic search and similarity-based recall
- **Dual Storage Benefits** â€“ Built-in redundancy, disaster recovery, and graceful degradation

The graph provides structure and relationships while vectors enable fuzzy semantic matching. Together, they create memory that's both precise and contextual.

## Why Graph + Vector?

### Traditional RAG (Vector Only)
```
Memory: "Chose PostgreSQL for reliability"
Query: "What database should I use?"
Result: âœ… Finds the memory
         âŒ Doesn't know WHY you chose it
         âŒ Can't connect to related decisions
```

### AutoMem (Graph + Vector)
```
Memory: "Chose PostgreSQL for reliability"
Graph: PREFERS_OVER MongoDB
       RELATES_TO "team expertise" memory
       DERIVED_FROM "boring technology" principle

Query: "What database should I use?"
Result: âœ… Finds the memory
        âœ… Knows your decision factors
        âœ… Shows related preferences
        âœ… Explains your reasoning pattern
```

## Real-World Performance

### Knowledge Graphs That Learn
```python
# After storing: "Migrated to PostgreSQL for operational simplicity"

AutoMem automatically creates:
â”œâ”€â”€ Entity: PostgreSQL (tagged: entity:tool:postgresql)
â”œâ”€â”€ Entity: operational simplicity (tagged: entity:concept:ops-simplicity)
â”œâ”€â”€ Pattern: "prefers boring technology" (reinforced)
â”œâ”€â”€ Temporal: PRECEDED_BY migration planning memory
â””â”€â”€ Similarity: SIMILAR_TO "Redis deployment" (both value simplicity)

# Next query: "Should we use Kafka?"
AI recalls:
- Your PostgreSQL decision
- Your "boring tech" pattern
- Related simplicity preferences
â†’ Suggests: "Based on your operational simplicity pattern, 
   consider RabbitMQ instead"
```

### Hybrid Search That Works
```bash
# Semantic + keyword + tags + time + importance scoring
GET /recall?query=database&tags=decision&time_query=last%20month

Returns memories ranked by:
- Vector similarity (0.64)
- Tag match (0.50)
- Recency (0.90)
- Exact keyword match (1.00)
Final score: 0.82 (weighted combination)
```

## Features

### Core Memory Operations

Everything your AI needs to build lasting knowledge:

- **ğŸ“ Store** â€“ Rich memories with metadata, importance scores, timestamps, and embeddings
- **ğŸ” Recall** â€“ Hybrid search combining vector similarity, keywords, tags, and time windows
- **âœï¸ Update** â€“ Modify existing memories with automatic embedding regeneration
- **ğŸ—‘ï¸ Delete** â€“ Clean removal from both graph and vector stores
- **ğŸ”— Associate** â€“ Create typed relationships between memories (11 relationship types)
- **ğŸ·ï¸ Filter** â€“ Tag-based queries with prefix and exact matching

### Memory Consolidation

AutoMem uses [neuroscience-inspired](https://pmc.ncbi.nlm.nih.gov/articles/PMC4648295/) consolidation cycles to keep memories relevant and organized:

- **â° Decay (Hourly)** â€“ Exponential relevance scoring based on age, access patterns, relationships, and importance
- **ğŸ’¡ Creative (Hourly)** â€“ Discovers surprising connections between memories during "REM-like" processing
- **ğŸ§© Cluster (Every 6 Hours)** â€“ Groups similar memories and generates meta-patterns
- **ğŸ—‚ï¸ Forget (Daily)** â€“ Archives low-relevance memories, permanently deletes extremely old unused ones

**Smart Forgetting:** Memories aren't immediately deleted. They're archived first (relevance 0.05-0.2), only removed if they drop below 0.05. This means wrong paths naturally fade (~30-45 days without use), while important connections survive longer.

### Background Intelligence

#### Enrichment Pipeline
Automatically enhances every memory:
- **Entity extraction** - People, projects, tools, concepts (with spaCy)
- **Auto-tagging** - `entity:<type>:<slug>` for structured queries
- **Summaries** - Lightweight snippets for quick scanning
- **Temporal links** - `PRECEDED_BY` to recent memories
- **Semantic neighbors** - `SIMILAR_TO` via cosine similarity
- **Pattern detection** - Reinforces emerging themes

#### Consolidation Engine
Keeps memory fresh over time:
- **Decay** (hourly) - Exponential relevance scoring
- **Creative** (hourly) - Discovers surprising associations
- **Cluster** (6-hourly) - Groups similar embeddings, generates meta-memories
- **Forget** (daily) - Archives/deletes low-relevance memories

### 11 Relationship Types

Build rich knowledge graphs:

| Type | Use Case | Example |
|------|----------|---------|
| `RELATES_TO` | General connection | Bug report â†’ Related issue |
| `LEADS_TO` | Causal relationship | Problem â†’ Solution |
| `OCCURRED_BEFORE` | Temporal sequence | Planning â†’ Execution |
| `PREFERS_OVER` | User preferences | PostgreSQL â†’ MongoDB |
| `EXEMPLIFIES` | Pattern examples | Code review â†’ Best practice |
| `CONTRADICTS` | Conflicting info | Old approach â†’ New approach |
| `REINFORCES` | Supporting evidence | Decision â†’ Validation |
| `INVALIDATED_BY` | Outdated info | Legacy docs â†’ Current docs |
| `EVOLVED_INTO` | Knowledge evolution | Initial design â†’ Final design |
| `DERIVED_FROM` | Source tracking | Implementation â†’ Spec |
| `PART_OF` | Hierarchical structure | Feature â†’ Epic |

## Quick Start

Choose your deployment path based on your needs:

### Option 1: Railway (Recommended for Production)

**Best for:** Production deployments, 24/7 availability, multi-device access

Deploy AutoMem with managed FalkorDB and Qdrant in under 60 seconds:

```bash
# Install Railway CLI
npm i -g @railway/cli

# Login and deploy
railway login
railway init
railway up
```

After deployment:
1. Set `AUTOMEM_API_TOKEN` in Railway dashboard
2. Copy your Railway URL (e.g., `https://automem-production.up.railway.app`)
3. Test with: `curl https://your-url/health`

ğŸ‘‰ **[Complete Deployment Guide](INSTALLATION.md#deployment)** â€“ Railway setup, environment variables, and configuration

### Option 2: Docker Compose (Recommended for Local Development)

**Best for:** Local testing, development, privacy-focused work

Run the full stack (AutoMem + FalkorDB + Qdrant) locally:

```bash
# Clone and start all services
git clone https://github.com/verygoodplugins/automem.git
cd automem
make dev

# Services will be available at:
# â€¢ API: http://localhost:8001
# â€¢ FalkorDB: localhost:6379
# â€¢ Qdrant: localhost:6333
```

### Option 3: Development Mode (API Only)

**Best for:** Quick testing without Docker, or when databases are remote

Run just the Flask API:

```bash
# Create virtual environment
python3 -m venv venv
source venv/bin/activate
pip install -r requirements-dev.txt

# Start API (requires existing FalkorDB/Qdrant)
PORT=8001 python app.py
```

**Next Steps:** [API Examples](#api-examples) | [Configuration Guide](INSTALLATION.md#configuration)

## API Examples

### Store a Memory
```bash
curl -X POST http://localhost:8001/memory \
  -H "Authorization: Bearer YOUR_TOKEN" \
  -H "Content-Type: application/json" \
  -d '{\n    "content": "Chose PostgreSQL over MongoDB for ACID compliance",
    "type": "Decision",
    "confidence": 0.95,
    "tags": ["database", "architecture"],
    "importance": 0.9,
    "metadata": {\n      "source": "architecture-meeting",
      "alternatives": ["MongoDB", "MySQL"],
      "deciding_factors": ["ACID", "team_expertise"]
    }
  }'
```

**Available memory types**: `Decision`, `Pattern`, `Preference`, `Style`, `Habit`, `Insight`, `Context` (default)
- **Explicit `type` recommended** when you know the classification
- **Omit `type`** to let enrichment auto-classify from content

### Recall Memories
```bash
# Hybrid search with tags and time
GET /recall?query=database&tags=decision&time_query=last%20month

# Semantic search with vector
GET /recall?embedding=0.12,0.56,...&limit=10

# Tag prefix matching (finds slack:U123:*, slack:channel-ops, etc.)
GET /recall?tags=slack&tag_match=prefix
```

### Create Relationship
```bash
curl -X POST http://localhost:8001/associate \
  -H "Authorization: Bearer YOUR_TOKEN" \
  -H "Content-Type: application/json" \
  -d '{\n    "memory1_id": "uuid-postgres-decision",
    "memory2_id": "uuid-mongodb-evaluation",
    "type": "PREFERS_OVER",
    "strength": 0.9
  }'
```

## Connect to AI Platforms

AutoMem integrates seamlessly with any AI assistant or application:

### ğŸ”Œ MCP (Model Context Protocol)

**For Local AI Tools** (Claude Desktop, Cursor, Claude Code):

Install the official MCP bridge to give your desktop AI tools persistent memory:

```bash
# One-command setup
npm install -g @verygoodplugins/mcp-automem
npx @verygoodplugins/mcp-automem setup
```

Your AI assistant can now store and recall memories automatically.

**For Cloud AI Platforms** (ChatGPT, Claude.ai, ElevenLabs):

Connect AutoMem to cloud services via the SSE sidecar:

- âœ… **ChatGPT** (with developer mode)
- âœ… **Claude.ai** web interface
- âœ… **Claude mobile app**
- âœ… **ElevenLabs Agents**

See the [MCP over SSE Setup Guide](docs/MCP_SSE.md) for detailed instructions.

**Resources:**
- ğŸ“¦ [NPM Bridge Package](https://www.npmjs.com/package/@verygoodplugins/mcp-automem)
- ğŸ“š [SSE Configuration Guide](docs/MCP_SSE.md)

### ğŸŒ Direct API Integration

Use AutoMem from any language or framework:

```python
import requests

# Store a memory
response = requests.post(
    "https://your-automem.railway.app/memory",
    headers={"Authorization": f"Bearer {token}"},
    json={"content": "Memory content", "importance": 0.8}
)
```

Perfect for custom integrations, backend services, or building your own AI assistant.

## What Makes AutoMem Different

### vs. Traditional RAG Systems
- âœ… **Rich Relationships** â€“ Not just "similar" matches, but explicit relationships like "causes", "prefers", "invalidates"
- âœ… **Temporal Intelligence** â€“ Knows what came before, what evolved from what, and how knowledge changes over time
- âœ… **Pattern Discovery** â€“ Automatically discovers and reinforces recurring themes across memories
- âœ… **Active Consolidation** â€“ Memories improve and organize over time, not just pile up

### vs. Vector-Only Databases
- âœ… **11 Relationship Types** â€“ Structured edges vs. cosine similarity alone
- âœ… **Background Intelligence** â€“ Automatic enrichment, clustering, and relevance decay
- âœ… **Hybrid Scoring** â€“ Vector similarity + keyword matching + tag overlap + temporal context + importance weighting
- âœ… **Graph Traversal** â€“ Navigate relationship chains, not just retrieve similar vectors

### vs. Building Your Own Memory System
- âœ… **Research-Validated** â€“ Implements proven principles from HippoRAG 2, A-MEM, MELODI, and ReadAgent
- âœ… **Production-Ready** â€“ Built-in authentication, admin tools, health monitoring, and backup systems
- âœ… **Battle-Tested** â€“ Robust enrichment pipeline, consolidation logic, and automatic retry mechanisms
- âœ… **Open Source** â€“ MIT license, deploy anywhere, extend freely

## Performance & Reliability

**Built for Real-World Production Use**

- âš¡ **Sub-second recall** â€“ Even with 100k+ memories
- ğŸ”„ **Concurrent writes** â€“ Background enrichment doesn't block API requests
- ğŸ›¡ï¸ **Graceful degradation** â€“ Works in graph-only mode if Qdrant is unavailable
- ğŸ” **Automatic retries** â€“ Failed enrichments queue for reprocessing
- ğŸ“Š **Health monitoring** â€“ `/health` and `/enrichment/status` endpoints
- ğŸ’¾ **Automated backups** â€“ Optional backup service for disaster recovery
- ğŸ” **Dual storage redundancy** â€“ Data persisted in both FalkorDB and Qdrant
- âœ… **Benchmark validated** â€“ Tested against LoCoMo (ACL 2024) with `make test-locomo`

## Configuration

### Essential Settings

**Required:**
- `AUTOMEM_API_TOKEN` â€“ Authentication for all endpoints (except `/health`)
- `FALKORDB_HOST` / `FALKORDB_PORT` â€“ Graph database connection

**Optional but Recommended:**
- `QDRANT_URL` / `QDRANT_API_KEY` â€“ Enable semantic vector search
- `OPENAI_API_KEY` â€“ Generate real embeddings (otherwise uses deterministic placeholders)
- `ADMIN_API_TOKEN` â€“ Required for admin endpoints like `/admin/reembed`

**Advanced Tuning:**
- `CONSOLIDATION_*_INTERVAL_SECONDS` â€“ Adjust decay, creative, cluster, and forget cycles
- `ENRICHMENT_*` â€“ Configure similarity thresholds, retry limits, and worker behavior

ğŸ‘‰ **[Complete Configuration Guide](INSTALLATION.md#configuration)** â€“ All environment variables with examples

## Documentation

**Get Started:**
- ğŸ“¦ **[Installation Guide](INSTALLATION.md)** â€“ Railway, Docker, and development setup
- ğŸš€ **[Quick Start](#quick-start)** â€“ Deploy in 60 seconds

**Integration:**
- ğŸŒ‰ **[MCP over SSE](docs/MCP_SSE.md)** â€“ Connect to ChatGPT, Claude, and ElevenLabs
- ğŸ”§ **[API Reference](docs/API.md)** â€“ Complete endpoint documentation with examples

**Operations:**
- ğŸ’¾ **[Monitoring & Backups](docs/MONITORING_AND_BACKUPS.md)** â€“ Health checks and disaster recovery
- ğŸ§ª **[Testing Guide](docs/TESTING.md)** â€“ Unit, integration, and benchmark tests
- ğŸ“Š **[LoCoMo Benchmark](docs/TESTING.md#locomo-benchmark)** â€“ ACL 2024 validation suite

**Migration:**
- ğŸ”„ **[Migration Guide](INSTALLATION.md#migration)** â€“ Move from MCP SQLite or other systems

**Learn More:**
- ğŸŒ **[automem.ai](https://automem.ai)** â€“ Official website and tutorials

## Community & Support

**Connect with Us:**
- ğŸŒ **[automem.ai](https://automem.ai)** â€“ Official website
- ğŸ™ **[GitHub Repository](https://github.com/verygoodplugins/automem)** â€“ Source code and discussions
- ğŸ“¦ **[NPM MCP Bridge](https://www.npmjs.com/package/@verygoodplugins/mcp-automem)** â€“ Official MCP integration
- ğŸ› **[Issue Tracker](https://github.com/verygoodplugins/automem/issues)** â€“ Bug reports and feature requests

## The Science Behind AutoMem

AutoMem isn't just inspired by researchâ€”it implements peer-reviewed principles from leading institutions:

**[HippoRAG 2](https://arxiv.org/abs/2502.14802)** (Ohio State, June 2025)  
Graph-vector hybrid architecture achieves **7% better associative memory** than pure vector RAG, approaching human long-term memory performance.

**[A-MEM](https://arxiv.org/abs/2502.12110)** (July 2025)  
Validates dynamic memory organization with Zettelkasten-inspired principlesâ€”exactly what AutoMem's pattern detection and clustering implement.

**[MELODI](https://arxiv.org/html/2410.03156v1)** (DeepMind, 2024)  
Demonstrates **8x memory compression** without quality loss through gist representationsâ€”AutoMem's summary generation follows these principles.

**[ReadAgent](https://arxiv.org/abs/2402.09727)** (DeepMind, 2024)  
Shows **20x context extension** via episodic memoryâ€”AutoMem's consolidation engine implements similar temporal organization.

**We didn't just read the papers. We built the system they describe.**

## Contributing

We welcome contributions from the community! Here's how to get involved:

1. **Fork** the repository on GitHub
2. **Create** a feature branch for your changes
3. **Add tests** for new functionality
4. **Submit** a pull request with a clear description

See our [Testing Guide](TESTING.md) for running the test suite locally.

## License

**MIT License** â€“ Because AI memory should be free and accessible to everyone.

---

## Ready to Transform Your AI?

Give your AI assistant the gift of human-like memory:

```bash
# Deploy to production in 60 seconds
railway up

# Or start locally
make dev
```

**AutoMem turns AI from a tool into a thinking partner.**

*Built with obsession. Validated by neuroscience. Powered by graph theory.*